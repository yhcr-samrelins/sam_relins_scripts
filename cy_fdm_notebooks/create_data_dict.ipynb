{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e9315bb-0c72-402a-a624-b2cd01840917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_num_description_column(col_name, table_name):\n",
    "    \"\"\"\n",
    "    Takes a column name and a table name, returning a string with descriptive \n",
    "    statistics for the column specified.\n",
    "\n",
    "    Calculates the mean, median, max, min and IQR for the specified column using \n",
    "    BigQuery SQL and returns a string with the results concatenated together.\n",
    "\n",
    "    Args:\n",
    "        col_name (str): The name of a the numeric column.\n",
    "        table_name (str): The name of the table containing the specified column.\n",
    "\n",
    "    Returns:\n",
    "        str: A string with the mean, median, max, min and IQR for the specified column.\n",
    "    \"\"\"\n",
    "    sql_query = f\"\"\"\n",
    "        WITH stats AS (\n",
    "            SELECT\n",
    "                AVG({col_name}) AS mean,\n",
    "                MAX({col_name}) AS max,\n",
    "                MIN({col_name}) AS min,\n",
    "                APPROX_QUANTILES({col_name}, 2)[OFFSET(1)] AS median,\n",
    "                APPROX_QUANTILES({col_name}, 4)[OFFSET(1)] AS q1,\n",
    "                APPROX_QUANTILES({col_name}, 4)[OFFSET(3)] AS q3\n",
    "            FROM `{table_name}`\n",
    "        )\n",
    "        SELECT CONCAT('Mean: ', CAST(mean AS STRING),  \n",
    "                      ', Median: ', CAST(median AS STRING), \n",
    "                      ', Max: ', CAST(max AS STRING), \n",
    "                      ', Min: ', CAST(min AS STRING),  \n",
    "                      ', IQR: ', CAST(q3 - q1 AS STRING))\n",
    "        FROM stats\n",
    "    \"\"\"\n",
    "    return pd.read_gbq(sql_query).iloc[0,0]\n",
    "\n",
    "\n",
    "def get_date_description_column(col_name, table_name):\n",
    "    \"\"\"\n",
    "    Takes a column name and a table name, returning a string with the min and max \n",
    "    dates.\n",
    "\n",
    "    Calculates the min and max dates for the specified column using BigQuery SQL \n",
    "    and returns a string with the results concatenated together.\n",
    "\n",
    "    Args:\n",
    "        col_name (str): The name of a date column.\n",
    "        table_name (str): The name of the table containing the specified column.\n",
    "\n",
    "    Returns:\n",
    "        str: A string with the min and max dates for the specified column.\n",
    "    \"\"\"\n",
    "    sql_query = f\"\"\"\n",
    "        WITH stats AS (\n",
    "            SELECT \n",
    "                MAX({col_name}) AS max_date, \n",
    "                MIN({col_name}) AS min_date \n",
    "            FROM `{table_name}`\n",
    "        )\n",
    "        SELECT\n",
    "            CONCAT('From: ', CAST(min_date AS STRING), \n",
    "                   ' To: ', CAST(max_date AS STRING))\n",
    "        FROM stats\n",
    "    \"\"\"\n",
    "    return pd.read_gbq(sql_query).iloc[0,0]\n",
    "\n",
    "\n",
    "def get_bool_description_column(col_name, table_name):\n",
    "    \"\"\"\n",
    "    Takes a column name and a table name, returning a the count of `True` and \n",
    "    `False` values.\n",
    "\n",
    "    Calculates the count of `True` and `False` values for the specified column \n",
    "    using BigQuery SQL and returns a string with the results concatenated \n",
    "    together.\n",
    "\n",
    "    Args:\n",
    "        col_name (str): The name of the boolean column.\n",
    "        table_name (str): The name of the table containing the specified column.\n",
    "\n",
    "    Returns:\n",
    "        str: A string with the count of `True` and `False` values for the \n",
    "             specified column.\n",
    "    \"\"\"\n",
    "    sql_query = f\"\"\"\n",
    "        WITH stats AS (\n",
    "            SELECT\n",
    "                COUNTIF({col_name} = TRUE) AS true_count,\n",
    "                COUNTIF({col_name} = FALSE) AS false_count\n",
    "            FROM `{table_name}`\n",
    "        )\n",
    "        SELECT\n",
    "            CONCAT('False: ', CAST(false_count AS STRING), \n",
    "                   ', True: ', CAST(true_count AS STRING))\n",
    "        FROM stats\n",
    "    \"\"\"\n",
    "    return pd.read_gbq(sql_query).iloc[0,0]\n",
    "\n",
    "\n",
    "def get_string_description_column(col_name, table_name):\n",
    "    sql_query = f\"\"\"\n",
    "        WITH top_entries AS (\n",
    "            SELECT {col_name}, COUNT(*) AS count\n",
    "            FROM `{table_name}`\n",
    "            GROUP BY {col_name}\n",
    "            ORDER BY count DESC\n",
    "            LIMIT 5 \n",
    "        ),\n",
    "        total_entries AS (\n",
    "            SELECT COUNT(DISTINCT {col_name}) AS total_count\n",
    "            FROM `{table_name}` \n",
    "        )\n",
    "        SELECT IF((SELECT total_count FROM total_entries) > 5, \n",
    "                   CONCAT('Top 5: ', STRING_AGG(CONCAT({col_name}, ': ', \n",
    "                          CAST(count AS STRING)), ', ')), \n",
    "                   STRING_AGG(CONCAT({col_name}, ': ', \n",
    "                              CAST(count AS STRING)), ', '))\n",
    "        FROM top_entries\n",
    "    \"\"\"\n",
    "    return pd.read_gbq(sql_query).iloc[0,0]\n",
    "\n",
    "\n",
    "def create_data_dict(dataset_id):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create a data dictionary table for a BigQuery dataset.\n",
    "    \n",
    "    Takes the ID of a BigQuery dataset and creates a data_dict table in the same \n",
    "    dataset. `data_dict` contains information about tables in the \n",
    "    dataset with names prefixed \" tbl_\" or \"cb_\":\n",
    "    table name, column name, data type, and a summary \n",
    "    description of each column. `description` column includes summary statistics \n",
    "    for numeric columns (mean, median, IQR, min,  max), the number of unique \n",
    "    values and top 5 values for string columns, the  date range for date \n",
    "    columns, and the count of True and False values for boolean columns. \n",
    "    \n",
    "    Args:\n",
    "        dataset_id (str): The ID of the BigQuery dataset.\n",
    "        \n",
    "    Output:\n",
    "        None - `data_dict` table is uploaded to biqquery dataset at \"dataset_id\"\n",
    "    \"\"\"\n",
    "    \n",
    "    client = bigquery.Client()\n",
    "    dataset_ref = client.dataset(dataset_id)\n",
    "    tables = list(client.list_tables(dataset_ref))\n",
    "    rows = []\n",
    "    table_count = 0\n",
    "    output_dict = {\n",
    "        \"table_name\": [],\n",
    "        \"column_name\": [],\n",
    "        \"data_type\": [],\n",
    "        \"description\": []\n",
    "    }\n",
    "    for table in tables:\n",
    "        if table.table_id.startswith(\"tbl_\") or table.table_id.startswith(\"cb_\"):\n",
    "            table_count += 1\n",
    "            print(f\"Processing table {table_count} of {len(tables)}: {table.table_id}\")\n",
    "            table_ref = dataset_ref.table(table.table_id)\n",
    "            table = client.get_table(table_ref)\n",
    "            for schema_field in tqdm(table.schema):\n",
    "                output_dict[\"table_name\"].append(table.table_id)\n",
    "                output_dict[\"column_name\"].append(schema_field.name)\n",
    "                output_dict[\"data_type\"].append(schema_field.field_type)\n",
    "                full_table_id = f\"{dataset_id}.{table.table_id}\"\n",
    "                if schema_field.field_type == \"STRING\":\n",
    "                    output_dict[\"description\"].append(\n",
    "                        get_string_description_column(schema_field.name, \n",
    "                                                      full_table_id) \n",
    "                    )\n",
    "                elif schema_field.field_type in [\"INTEGER\", \"FLOAT\", \"NUMERIC\"]:\n",
    "                    output_dict[\"description\"].append(\n",
    "                        get_num_description_column(schema_field.name, \n",
    "                                                      full_table_id) \n",
    "                    )\n",
    "                elif schema_field.field_type in [\"DATE\", \"TIMESTAMP\", \"DATETIME\"]:\n",
    "                    output_dict[\"description\"].append(\n",
    "                        get_date_description_column(schema_field.name, \n",
    "                                                      full_table_id) \n",
    "                    )\n",
    "                elif schema_field.field_type in [\"BOOL\", \"BOOLEAN\"]:\n",
    "                    output_dict[\"description\"].append(\n",
    "                        get_bool_description_column(schema_field.name, \n",
    "                                                      full_table_id) \n",
    "                    )\n",
    "    output_df = pd.DataFrame(output_dict)\n",
    "    output_df.to_gbq(f\"{dataset_id}.data_dict\", progress_bar=False)\n",
    "    print(\"Finished creating data_dict table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77b4e1a7-785c-4b9b-b9c7-bd314bd2b2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 1 of 1: tbl_autism_amalgamated_ptl_oct2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:18<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating data_dict table\n"
     ]
    }
   ],
   "source": [
    "create_data_dict(\"CB_FDM_ASD_PTL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d34c7f-6068-44d8-be6a-13a17cf55eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b1c565d-5a80-40ad-a323-7067636ec8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Top 5: Kilmeny Surgery: 135, Modality pooled: 105, Ashcroft Surgery: 98, Holycroft Surgery: 96, Farfield Group Practice: 93'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_string_description_column(\"gp\", \"CB_FDM_ASD_PTL.tbl_autism_amalgamated_ptl_oct2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2c9c69-9742-41a8-b2f4-fad8901b1ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-FDMEnv-py",
   "name": "r-cpu.4-1.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-1:m90"
  },
  "kernelspec": {
   "display_name": "Python [conda env:FDMEnv]",
   "language": "python",
   "name": "conda-env-FDMEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
