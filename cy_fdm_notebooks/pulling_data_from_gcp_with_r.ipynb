{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8289500-0f9c-42d0-aea7-da6bc1d394ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(bigrquery)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baaa49e-90e0-4f8f-af97-32a22e9a9c1e",
   "metadata": {},
   "source": [
    "# Intro to bigrquery\n",
    "\n",
    "The following is a quick intro to the `bigrquery` R library. More specifically, its a guide to getting your data out of the BigQuery database and into your R notebooks. The workflow we'll be using requires your queries to be scripted in SQL: \n",
    "\n",
    "## SQL Basics\n",
    "\n",
    "Mostly you'll be sending instructions to the BigQuery databse in the form of `SELECT * FROM`. If that means absolutely nothing to you, or you want to brush up your SQL skills, I recommend the following courses on Kaggle. They're particularly good in this case as they are taught using the BigQuery SQL syntax, so it's more-or-less exactly the tool you'll be using here. The lessons are scripted using the python BigQuery API, but don't let that put you off - the actual nuts-and-bolts bits of the lessons, the bits that you'll be interacting with are all SQL Hey, it might be useful as an intro to the Python API if you ever want to use that (the python API is leagues better than the R one, so I'd recommend using that if you ever want to properly pipeline any data using BigQuery).\n",
    "\n",
    "* Intro to SQL - https://www.kaggle.com/learn/intro-to-sql\n",
    "* Advanced SQL - https://www.kaggle.com/learn/advanced-sql\n",
    "\n",
    "On a related note, if you're not familiar with Kaggle I highly recommend giving it a look. It's an interactive data science platform where you can build and run code, look at other people's work, and enter machine learning competitions. It's an amazing resource for anybody interested in data science (and particularly machine learning)\n",
    "\n",
    "## Downloading a Table from BigQuery\n",
    "\n",
    "Once you have SQL down, pick one of the tables in your BigQuery environment to take a gander at. You'll need the full table id, so thats:\n",
    "\n",
    "1. the project id - that is always \"yhcr-prd-phm-bia-core\" (catchy eh?!)\n",
    "2. your dataset id - usually in the form \"CY_XXXX_surname\", the Xs being numbers and \"surname\" being your surname. You might have access to other datasets with a totally different naming structure, but you get the idea\n",
    "3. your table id - this will differ depending on the table\n",
    "\n",
    "You should end up with a table ID that looks something like \"yhcr-prd-phm-bia-core.CY_1715_example_surname.tbl_example_table\". You can then stick it in this basic SQL query to pull the whole table:\n",
    "\n",
    "```\n",
    "SELECT * \n",
    "FROM `yhcr-prd-phm-bia-core.CY_1715_example_surname.tbl_example_table`\n",
    "```\n",
    "\n",
    "**Quick warning**: Always stick your table names inside backticks \\`like this\\`. BigQuery can get confused with hyphens (-) in queries and, helpfully, YHCR have decided to give us a project name with hyphens in it, so the backticks avoid the database engine thinking the backticks are subtraction operators. \n",
    "\n",
    "Once you have your sql query, store it as a string like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d78322-a154-489c-80cc-b45915d49d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query <- \"SELECT * FROM `yhcr-prd-phm-bia-core.CY_1715_example_surname.tbl_example_table`\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aa5473-f609-44bd-b656-94d8b2e0e0e5",
   "metadata": {},
   "source": [
    "You can then send your query to the BigQuery database engine like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3438b09-83b8-44d4-89f5-f774d868b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id <- \"yhcr-prd-phm-bia-core\"\n",
    "\n",
    "my_query <- bq_project_query(project_id, sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fceea4d-3328-402e-a41f-70a4727a93e5",
   "metadata": {},
   "source": [
    "That tells BigQuery to run your SQL instructions, and store the output in a temporary location in the cloud that `my_query` points to. Then, you can download the information in `my_query` like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90618fa6-3be2-4e58-99b2-a8f5d61f3ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "table <- bq_table_download(my_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cf1da1-b9c5-4d29-85fe-a9e2cdb92c35",
   "metadata": {},
   "source": [
    "And that's all there is to it really! The table you've downloaded your table into an R \"tibble\" object - basically the dataframe that you're all used to. You can now go ahead and use it like you would any other dataframe you've loaded. Enjoy!"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-REnv-r",
   "name": "r-cpu.4-1.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-1:m90"
  },
  "kernelspec": {
   "display_name": "R [conda env:REnv]",
   "language": "R",
   "name": "conda-env-REnv-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
