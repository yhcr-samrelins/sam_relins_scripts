{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dca42b56-d8e5-4555-88c4-953faee5cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FDMBuilder.FDM_helpers import *\n",
    "from thefuzz import process, fuzz\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad6f007-a718-42b5-8279-1c11f7bd9644",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableMatcher:\n",
    "    \n",
    "    def __init__(self, table_a_id, table_b_id, dataset_id, \n",
    "                 suffix_prop=0.95, new_table_name=None):\n",
    "        self.table_a_id = table_a_id\n",
    "        self.table_b_id = table_b_id\n",
    "        self.dataset_id = dataset_id\n",
    "        self.suffix_prop = 0.95\n",
    "        self.new_table_name = new_table_name\n",
    "        self.build_matched_colnames_df(suffix_prop)\n",
    "        \n",
    "        \n",
    "    def build_matched_colnames_df(self, suffix_prop):\n",
    "        \n",
    "        orig_names_a = list(get_table_schema_dict(self.table_a_id).keys())\n",
    "        wo_prefix_names_a = self._remove_prefix_suffix(orig_names_a, \n",
    "                                                       prop=suffix_prop)\n",
    "        orig_names_b = list(get_table_schema_dict(self.table_b_id).keys())\n",
    "        wo_prefix_names_b = self._remove_prefix_suffix(orig_names_b, \n",
    "                                                       prop=suffix_prop)\n",
    "        matches_df = pd.DataFrame(dict(\n",
    "            orig_name_a = orig_names_a + ([None] * len(orig_names_b)),\n",
    "            name_a = wo_prefix_names_a + ([None] * len(orig_names_b)),\n",
    "            orig_name_b = ([None] * len(orig_names_a)) + orig_names_b,\n",
    "            name_b = ([None] * len(orig_names_a)) + wo_prefix_names_b,\n",
    "            match_score = 0\n",
    "        ))\n",
    "\n",
    "        for name_to_match, orig_name_to_match in zip(wo_prefix_names_b, \n",
    "                                                     orig_names_b):\n",
    "            matches = process.extract(name_to_match, wo_prefix_names_a, limit=5)\n",
    "            for match, score in matches:\n",
    "                if score < 80:\n",
    "                    continue\n",
    "                match_mask = matches_df.name_a == match\n",
    "                existing_score = matches_df[match_mask].match_score.values[0]\n",
    "                if score > existing_score:\n",
    "                    match_loc = matches_df[match_mask].index\n",
    "                    matches_df.loc[match_loc, \"name_b\"] = name_to_match\n",
    "                    matches_df.loc[match_loc, \"orig_name_b\"] = orig_name_to_match\n",
    "                    matches_df.loc[match_loc, \"match_score\"] = score\n",
    "\n",
    "        matches_df.sort_values(\"match_score\", ascending=False, inplace=True)\n",
    "        duplicated_name_b_mask = matches_df.name_b.duplicated()\n",
    "        set_to_none_mask = matches_df.name_a.notna() & duplicated_name_b_mask\n",
    "        set_to_none_cols = [\"orig_name_b\", \"name_b\", \"match_score\"]\n",
    "        matches_df.loc[set_to_none_mask, set_to_none_cols] = None, None, 0\n",
    "        duplicated_name_b_mask = matches_df.name_b.duplicated()\n",
    "        name_b_none_mask = matches_df.name_b.isna()\n",
    "        matches_df = matches_df[~duplicated_name_b_mask | name_b_none_mask]\n",
    "        matches_df.sort_values([\"name_a\", \"name_b\"], inplace=True)\n",
    "\n",
    "        self.colname_matches = matches_df\n",
    "    \n",
    "    \n",
    "    def get_unmatched_names(self):\n",
    "        name_a_null_mask = self.colname_matches.name_a.isna()\n",
    "        name_b_null_mask = self.colname_matches.name_b.isna()\n",
    "        unmatched_mask = name_a_null_mask | name_b_null_mask\n",
    "        name_cols = [\"name_a\", \"name_b\"]\n",
    "        return self.colname_matches[unmatched_mask][name_cols]\n",
    "    \n",
    "    \n",
    "    def match_tables(self):\n",
    "        def get_table_a_select_strings(row):\n",
    "            if row.match_score == 100 or row.name_b is None:\n",
    "                return row.orig_name_a + \" AS \" + row.name_a\n",
    "            elif row.match_score > 0:\n",
    "                return row.orig_name_a + \" AS \" + row.name_b\n",
    "            elif row.name_a is None:\n",
    "                return \"NULL AS \" + row.name_b\n",
    "        table_a_select_strings = (self\n",
    "                                  .colname_matches\n",
    "                                  .apply(get_table_a_select_strings, axis=1))\n",
    "        table_a_select_string = \", \".join(table_a_select_strings.values)\n",
    "\n",
    "        def get_table_b_select_strings(row):\n",
    "            if row.name_b is None:\n",
    "                return \"NULL AS \" + row.name_a\n",
    "            else:\n",
    "                return row.orig_name_b + \" AS \" + row.name_b\n",
    "        table_b_select_strings = (self\n",
    "                                  .colname_matches\n",
    "                                  .apply(get_table_b_select_strings, axis=1))\n",
    "        table_b_select_string = \", \".join(table_b_select_strings.values)\n",
    "        sql = f\"\"\"\n",
    "            SELECT {table_a_select_string}\n",
    "            FROM `{self.table_a_id}`\n",
    "            UNION ALL\n",
    "            SELECT {table_b_select_string}\n",
    "            FROM `{self.table_b_id}`\n",
    "        \"\"\"\n",
    "        table_a_alias = self.table_a_id.split(\".\")[-1]\n",
    "        table_b_alias = self.table_b_id.split(\".\")[-1]\n",
    "        if self.new_table_name is None:\n",
    "            destination_table_id = \".\".join([PROJECT, \n",
    "                                            self.dataset_id, \n",
    "                                            table_a_alias + \"-\" + table_b_alias])\n",
    "        else:\n",
    "            destination_table_id = \".\".join([PROJECT, \n",
    "                                            self.dataset_id, \n",
    "                                            self.new_table_name])\n",
    "        run_sql_query(sql, destination=destination_table_id)\n",
    "    \n",
    "                      \n",
    "    def add_match(self, name_a, name_b):\n",
    "        match_a_mask = self.colname_matches.name_a == name_a\n",
    "        match_b_mask = self.colname_matches.name_b == name_b\n",
    "        orig_name_b = self.colname_matches[match_b_mask].orig_name_b.values[0]\n",
    "        if not match_a_mask.any():\n",
    "            raise ValueError(f\"No column named {name_a}\")\n",
    "        elif not match_b_mask.any():\n",
    "            raise ValueError(f\"No column named {name_b}\")\n",
    "        elif self.colname_matches[match_a_mask].name_b.values[0] != None:\n",
    "            raise ValueError(f\"Already a match for {name_a}\")\n",
    "        elif self.colname_matches[match_b_mask].name_a.values[0] != None:\n",
    "            raise ValueError(f\"Already a match for {name_b}\")\n",
    "        cols_to_set = [\"name_b\", \"orig_name_b\", \"match_score\"]\n",
    "        set_values = name_b, orig_name_b, 1\n",
    "        self.colname_matches.loc[match_a_mask, cols_to_set] = set_values\n",
    "        self.colname_matches = self.colname_matches[~match_b_mask]\n",
    "            \n",
    "            \n",
    "    def _find_prefix_suffix(self, names, prop):\n",
    "        return_chars = []\n",
    "        loop_idx = 0\n",
    "        continue_search = True\n",
    "        is_prefix = None\n",
    "        while continue_search:\n",
    "            char_counts = collections.Counter([name[loop_idx] \n",
    "                                               for name in names\n",
    "                                               if len(name) > abs(loop_idx)])\n",
    "            most_common_char, n_appears = char_counts.most_common(1)[0]\n",
    "            prop_same = n_appears / char_counts.total()\n",
    "            if prop_same > prop: \n",
    "                if loop_idx < 0:\n",
    "                    return_chars.insert(0, most_common_char)\n",
    "                    is_prefix = False \n",
    "                else:\n",
    "                    return_chars.append(most_common_char)\n",
    "                    is_prefix = True \n",
    "                if loop_idx < 0:\n",
    "                    loop_idx -= 1\n",
    "                else:\n",
    "                    loop_idx += 1\n",
    "            elif loop_idx == 0:\n",
    "                loop_idx = -1\n",
    "            else:\n",
    "                continue_search = False\n",
    "        return \"\".join(return_chars), is_prefix\n",
    "\n",
    "\n",
    "    def _remove_prefix_suffix(self, names, prop=0.95):\n",
    "        chars_to_remove, is_prefix = self._find_prefix_suffix(names, prop)\n",
    "        if is_prefix:\n",
    "            output_names = [name[len(chars_to_remove):] \n",
    "                            if chars_to_remove in name else name \n",
    "                            for name in names]\n",
    "        elif is_prefix == False:\n",
    "            output_names = [name[:-len(chars_to_remove)] \n",
    "                            if chars_to_remove in name else name \n",
    "                            for name in names]\n",
    "        else:\n",
    "            output_names = names\n",
    "        return output_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b9f6c219-16ec-4478-bc49-b04efff769b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SUS_Airedale_AE_20190201_to_20220131',\n",
       " 'SUS_Airedale_AE_20210401_to_20220131',\n",
       " 'SUS_Airedale_APC_010415_to_310119',\n",
       " 'SUS_Airedale_APC_20190201_to_20200630',\n",
       " 'SUS_Airedale_APC_20200701_to_20220131',\n",
       " 'SUS_Airedale_AdmittedPatentCare_010415_to_310119',\n",
       " 'SUS_Airedale_ECDS_010415_to_310119',\n",
       " 'SUS_Airedale_OP_20190201_to_20200630',\n",
       " 'SUS_Airedale_OP_20200701_to_2022013',\n",
       " 'SUS_Airedale_OP_20210401_to_20220131',\n",
       " 'SUS_Airedale_OutPatients_010415_to_310119',\n",
       " 'SUS_Airedale__AandE_010415_to_310119',\n",
       " 'SUS_BRI_APC_20200401_to_20220321',\n",
       " 'SUS_BRI_AccidentAndEmergency_010415_to_300619 ',\n",
       " 'SUS_BRI_AdmittedPatientCare_010415_to_300619_Part1',\n",
       " 'SUS_BRI_AdmittedPatientCare_010415_to_300619_Part2',\n",
       " 'SUS_BRI_EC_BackwardCompatible_20200401_to_20220322',\n",
       " 'SUS_BRI_EC_Backward_Compatible_010415_to_300619 ',\n",
       " 'SUS_BRI_OP_20200401_to_20220322',\n",
       " 'SUS_BRI_OutPatients_010415_to_300619',\n",
       " 'SUS_Calderdale_AE_AdditionalFields',\n",
       " 'SUS_Calderdale_APCCHFTOutputPart1_010417_to_310620',\n",
       " 'SUS_Calderdale_APCCHFTOutputPart2_010417_to_310620',\n",
       " 'SUS_Calderdale_APC_AdditionalFields',\n",
       " 'SUS_Calderdale_AandECHFTOutput_010417_to_311217',\n",
       " 'SUS_Calderdale_CriticalCare_20190130_to_20210930',\n",
       " 'SUS_Calderdale_ECDSBackwardsCompatibleOutput_010718_to_310520',\n",
       " 'SUS_Calderdale_EmergencyCare_20190401_to_20210930',\n",
       " 'SUS_Calderdale_InpatientPart1_20190401_to_20210930',\n",
       " 'SUS_Calderdale_InpatientPart2_20190401_to_20210930',\n",
       " 'SUS_Calderdale_OPOutput__010417_to_310620',\n",
       " 'SUS_Calderdale_Outpatient_20190401_to_20210930']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staging_dataset = CLIENT.get_dataset(\"CY_STAGING_DATABASE\")\n",
    "\n",
    "staging_tables = list(CLIENT.list_tables(staging_dataset))\n",
    "\n",
    "sus_table_ids = [table.table_id for table in staging_tables\n",
    "                 if table.table_id[:3] == \"SUS\"]\n",
    "\n",
    "sus_table_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6379a3-882e-4fd8-9616-de0c080e210c",
   "metadata": {},
   "source": [
    "## A & E tables\n",
    "\n",
    "two tables look v similar:\n",
    "\n",
    "    'SUS_Airedale_AE_20190201_to_20220131'\n",
    "    'SUS_Airedale_AE_20210401_to_20220131'\n",
    "    \n",
    "easily matched:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "58f3c21c-a218-42a4-a862-5b3cce0ed2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_ae_1 = \".\".join([PROJECT, \n",
    "                     \"CY_STAGING_DATABASE\", \n",
    "                     'SUS_Airedale_AE_20190201_to_20220131']) \n",
    "air_ae_2 = \".\".join([PROJECT, \n",
    "                     \"CY_STAGING_DATABASE\", \n",
    "                     'SUS_Airedale_AE_20210401_to_20220131']) \n",
    "table_matcher = TableMatcher(table_a_id = air_ae_1,\n",
    "                             table_b_id = air_ae_2,\n",
    "                             dataset_id = \"CY_SUS_DATA_TESTS\",\n",
    "                             new_table_name=\"air_ae_joined\")\n",
    "table_matcher.match_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9731e3fa-7b8e-44e8-9b70-27b3fd10ef0b",
   "metadata": {},
   "source": [
    "Naming of above two tables suspicious - looks like second table is duplicate of last 9 or so months of first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "36015299-ef8a-41af-8b25-ff80a7266302",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_ae_joined = \".\".join([PROJECT, \n",
    "                     \"CY_SUS_DATA_TESTS\", \n",
    "                     'air_ae_joined']) \n",
    "air_ae_df = pd.read_gbq(air_ae_joined)\n",
    "air_ae_df = air_ae_df.iloc[:-2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7492c59e-5891-49f0-bd70-66fbe63b0243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1769"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_cols = [\"Arrival_Date\", \"Nhs_No\"]\n",
    "duplicates_mask = air_ae_df[dup_cols].duplicated()\n",
    "# after_apr_2021 = pd.to_datetime(air_ae_df.Arrival_Date) > pd.to_datetime(\"2021-04-01\") \n",
    "# air_ae_df[duplicates_mask & after_apr_2021]\n",
    "duplicates_mask.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05149868-7d18-43ce-bc4f-2efc3d9975d7",
   "metadata": {},
   "source": [
    "pretty sure they are duplicates!\n",
    "\n",
    "There's another A&E table for airdale:\n",
    "\n",
    "    'SUS_Airedale__AandE_010415_to_310119'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "95b49ec4-7395-4931-9c9e-f4b98959d15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_a</th>\n",
       "      <th>name_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Acc_Status_SnmdCt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Access_Info_SnmdCt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Activity_Treat_Function</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Acuity_SnmdCt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Age_At_Cds</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>None</td>\n",
       "      <td>UDF1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>None</td>\n",
       "      <td>UDF2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>None</td>\n",
       "      <td>UDF3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>None</td>\n",
       "      <td>UDF4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>None</td>\n",
       "      <td>datasetref</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name_a      name_b\n",
       "35         Acc_Status_SnmdCt        None\n",
       "37        Access_Info_SnmdCt        None\n",
       "100  Activity_Treat_Function        None\n",
       "56             Acuity_SnmdCt        None\n",
       "53                Age_At_Cds        None\n",
       "..                       ...         ...\n",
       "196                     None        UDF1\n",
       "197                     None        UDF2\n",
       "198                     None        UDF3\n",
       "199                     None        UDF4\n",
       "359                     None  datasetref\n",
       "\n",
       "[307 rows x 2 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_ae_19 = \".\".join([PROJECT, \n",
    "                     \"CY_STAGING_DATABASE\", \n",
    "                     'SUS_Airedale_AE_20190201_to_20220131']) \n",
    "air_ae_15 = \".\".join([PROJECT, \n",
    "                     \"CY_STAGING_DATABASE\", \n",
    "                     'SUS_Airedale__AandE_010415_to_310119']) \n",
    "table_matcher_2 = TableMatcher(table_a_id = air_ae_19,\n",
    "                             table_b_id = air_ae_15,\n",
    "                             dataset_id = \"CY_SUS_DATA_TESTS\",\n",
    "                             new_table_name=\"air_ae_joined\")\n",
    "table_matcher_2.get_unmatched_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3846257f-2d46-4e01-82ab-6b25444e2bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_ma"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-FDMEnv-py",
   "name": "r-cpu.4-1.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-1:m90"
  },
  "kernelspec": {
   "display_name": "Python [conda env:FDMEnv]",
   "language": "python",
   "name": "conda-env-FDMEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
