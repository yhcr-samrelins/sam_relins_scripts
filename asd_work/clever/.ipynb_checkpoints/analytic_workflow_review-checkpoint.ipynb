{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc6a40d3-0113-4956-ab0b-faa0d887790a",
   "metadata": {},
   "source": [
    "# Analytic Workflow Review\n",
    "\n",
    "So, I've done my best to go through and test as much of your script as I can. This is a pretty complicated workflow, plus it's missing a lot of the code for repeated parts of the logic, so I've only been able to properly dive into a small part of the whole picture. As a basic summary/TLDR of what follows, I think we should have a discussion about what we're trying to achieve here and re-format a lot of the process: it's quite hard to properly figure out exactly what we have here, and what I can figure out does seem to have a few issues which may lead to some problematic outputs.\n",
    "\n",
    "I'm conscious that we're just trying to show end users what we have in our data, and have them poke holes in it, so you aren't too concerned about provenence/QA at this point. I'm still really struggling with the ethics/risks of a lot of this if I'm honest. In this particular case, we're doing a couple of big things that I think could lead to bad results:\n",
    "\n",
    "1. We're defining cohorts i.e. \"speech\"/\"vision\"/\"asd\" cohorts\n",
    "2. We're deriving our own observations from the data i.e. the concept of an encounter, when that first happened\n",
    "\n",
    "The ONLY way to properly scrutinise and diagnose issues with these processes is to carefully scrutinise the logic generating the data that is feeding CLEVER, and the end users won't be doing any of that. As such we need to be certain that we understand properly the implications of any decisions we take when cutting up the data, and adding our own observations, and I'm not sure we do. For example:\n",
    "\n",
    "* In defining a cohort, we're deciding what data NOT to show the end users. It's far less likely they can say with confidence that data is missing, or that our estimates for the number of people of type XXX or YYY are incorrect. Far more likely, they'll just trust that our logic stands, or the data is structured such that we're just representing information that is recorded at source, rather than manipulating it ourselves i.e. they'll think that \"vision\" or \"speech\" is coded for explicitly in the data, rather us generating those concepts ourselves\n",
    "* It's very hard to detect small errors when aggregating data that has been merged/manipulated as much as this has - small errors are non-obvious in large datasets, but when we start joining data and estimating subsets/intersections of different groups, those errors are compounded and can be many orders of magnitude larger. The logic of showing this to pratitioners is that it's novel, so I don't follow the logic that they'll be wowed and super interested in all this exciting new information but, at the same time, be able to point out obvious issues with it because it's their bread and butter\n",
    "* I don't think anybody in Connected Bradford is certain what any of the observations in the primary care data actually mean in a real sense - how they end up being entered on the system in the way they are - which observations are system generated - who enters what - how they came to be organised the way they are. I'm worried that some problematic assumptions could lead to wild miscalculations in numbers of patients, times of encounters, demographics individuals belong to etc.\n",
    "\n",
    "I really don't think these issues can be fixed by showing end users visualisations of our data. Those visualisations are backed up by a lot of moving and changing behind the scenes, and all that needs to be plainly laid out in logic to be able to identify errors in judgement there, and we need people capable of scrutinising that logic. I really struggled following a lot of the workflow (as you'll see below), so I'm not sure we have the former, and can't speak for the latter.\n",
    "\n",
    "I'll leave my concerns there for now - particularly as writing really ins't my strong point, and the vast amount of unknowns involved in this project make it really hard for me to articulate all the worries I have about using this data! The following is the review I've done of your analytic workflow:\n",
    "\n",
    "I've taken the word document you provided and re-formatted it so it can be run in a notebook. I try my hardest to encourage everybody to document their workflow this way, as a notebook is as expressive as a word document, but you can run code in it - it makes everything 10 times easier to follow and review/replicate if you have to hand the work over at any point. \n",
    "\n",
    "I've put your comments/text in red italics and then added my own comments in regular text format. They're rough notes - I had hoped to write them up in full prose, but ran out of time. Hopefully they still make sense, but we can discuss later if not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e981a2-8fa9-4912-995b-26eef433520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5401e2-950c-4e55-af9f-61f3dd9b625f",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "## *Context 1: Primary Care*\n",
    "\n",
    "***Goal**: Extract all GP visits that happened for CYP under 19 years old and find subsets in this cohort who have discussed any of the risk factors for Autism during those encounters*\n",
    "\n",
    "***Step 0**: Identify codes for the risk factor. Here we only select codes that have a valid_end_date within five years old. Older concepts are discarded for the purpose of this analysis.*\n",
    "\n",
    "***Example risk factor**: Speech and language* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde217ef-9f84-41ea-acd5-a0647a8fb893",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE `CB_1741_Relins.speech_codes` AS\n",
    "SELECT * FROM `CB_CDM_VOCAB.concept`\n",
    "WHERE (valid_end_date > CAST('2017-12-30' AS DATE)) AND \n",
    "    (concept_name LIKE '%speech%' OR concept_name LIKE '%Speech%')\n",
    "ORDER BY valid_end_date ASC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174ae137-9366-494c-b5a7-45d303a64d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_codes_sql = \"\"\"\n",
    "SELECT * FROM `CB_1741_Relins.speech_codes`\n",
    "\"\"\"\n",
    "project=\"yhcr-prd-phm-bia-core\"\n",
    "speech_codes = pd.read_gbq(speech_codes_sql, project_id=project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fcabc3-a0d4-41db-a04b-055cff1f4cbb",
   "metadata": {},
   "source": [
    "A lot of complexity is tied up in this first step. It isn't clear to me exactly what is being defined by \"speech\" (or indeed \"vision\") and I certainly don't have the expertise to criticise a codelist even if it were clear. I'm also not confident that doing a keyword search over the concept table is a good way of deriving a codelist - it leaves me with a lot of concerns that are hard to elaborate on here concicely but a flavour is:\n",
    "\n",
    "* I don't know how thorough/reliable the descriptions in the concept dataset is - there could be many speech/vision related concepts that aren't properly described in the `concept_name`\n",
    "* We're collecting together many different coding paradigms (SNOMED, ICD10 etc) that may not have been calibrated well, so we might be capturing a lot of poorly harmonised information\n",
    "* The concept tables draw together diagnoses/observations/administrative information/procedures - all of which will have very different data generating processes, none of which are well understood or validated - I really worry that drawing together such disparate groups of information compounds the risk of making a lot of invalid assumptions\n",
    "\n",
    "I think it would be good to explore other approaches. As far as I'm aware, the primary care data is all coded in SNOMED concepts, so we could use the opencodelists.org site to find curated condition lists and work from those - that would at least provide some air cover that we know what we're looking for in the code tables.\n",
    "\n",
    "It might be easier to discuss this in person. For the moment, we'll assume the overall approach of keyword concept searching is valid and look at the data from there:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc81fd0-738b-469d-abd0-fadf9c0b8354",
   "metadata": {},
   "source": [
    "\n",
    "* There are an extra 29 codes when running the script over the new `concept` table in `CB_CDM_VOCAB`\n",
    "* all of the \"domains\" are included, was this intentional? They are restricted to \"Observation\" and \"Procedure\" in the speech dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31deb8c-3852-4192-9ec1-7ed4e0b3ff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "speech_codes.domain_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c797e73-33d1-4354-9ae6-91b3ffb236e7",
   "metadata": {},
   "source": [
    "* some of the entries have an \"invalid reason\" which presumably means they shouldn't be included?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dc0d55-1107-40af-89f5-b87f1bdc390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_codes.invalid_reason.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38db2e17-a5c3-4cec-b9cf-318842733cef",
   "metadata": {},
   "source": [
    "* some entries look like they don't relate to the subject's speech/language directly - might be good to see values for the numbers of observations taken using these codes - there may be large numbers of individuals included in the cohort under dubious codes - if we're using these codes as inclusion criteria for our cohort, we're suggesting we've figured out a \"speech and language\" baseline which I don't think we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dac878-6a7c-41d0-ac2e-59e0081f5b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_cols = [\"concept_id\", \"domain_id\", \"concept_name\"]\n",
    "odd_codes = [4118542, 4140321, 3284050, 4173920, 37396617, 3423432]\n",
    "speech_codes[concept_cols][speech_codes.concept_id.isin(odd_codes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d01b02-df2e-47ab-8231-af4aab5f2e95",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "*Similar step for eye and vision codes:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc15d90f-6347-4ff6-a893-0ea18e4a5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE `CB_1741_Relins.vision_codes` AS\n",
    "SELECT * FROM `CB_CDM_VOCAB.concept`\n",
    "WHERE (valid_end_date > CAST('2017-12-30' AS DATE)) AND \n",
    "    (LOWER(concept_name) LIKE '%vision%' OR LOWER(concept_name) LIKE '%eye%') AND \n",
    "    domain_id IN(\"Observation\", \"Procedure\") AND \n",
    "    LOWER(concept_name) NOT LIKE '%adult%' AND \n",
    "    LOWER(concept_name) NOT LIKE '%revision%' AND \n",
    "    LOWER(concept_name) NOT LIKE '%provision%' AND \n",
    "    LOWER(concept_name) NOT LIKE '%supervision%' AND \n",
    "    LOWER(concept_name) NOT LIKE '%division%'\n",
    "ORDER BY valid_end_date ASC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917e2948-8b24-4f2e-8610-26035cfc4e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_codes_sql = \"\"\"\n",
    "SELECT * FROM `CB_1741_Relins.vision_codes`\n",
    "\"\"\"\n",
    "project=\"yhcr-prd-phm-bia-core\"\n",
    "vision_codes = pd.read_gbq(vision_codes_sql, project_id=project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ac172d-6a35-402b-9101-37b0d50b7733",
   "metadata": {},
   "source": [
    "As I'm sure can be intuited, I have the same overall concerns as above. Again, assuming the approach is valid:\n",
    "\n",
    "* there are another 315 codes using the new concept table\n",
    "* more codes with an \"invalid_reason\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d610586-3d11-40be-a198-55c5f23d0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_codes.invalid_reason.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a96e070-48b2-48ec-b0a1-8ec3a0bb8016",
   "metadata": {},
   "source": [
    "* some of the codes might not make sense again, 1911 seem to relate to eyelids/eyebrows which isn't so much vision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfdf45a-cb73-4bdf-9258-05be809f776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_strings = [\"eyelid\", \"eyebrow\"]\n",
    "problem_entries = (\n",
    "    vision_codes. \n",
    "    concept_name.\n",
    "    apply(lambda x: any(string in x.lower() for string in problem_strings))\n",
    ")\n",
    "vision_codes[concept_cols][problem_entries]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15981c6c-488b-4b94-958d-846c96d8204d",
   "metadata": {},
   "source": [
    "* lots of other codes relate to procedures on eyes that may not imply any issues with vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7539e0-3671-4386-b991-81d3f481ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_vision_entries = [3247127, 4218754, 3328617, 4144827, 4003369, 1005509, 35822480]\n",
    "vision_codes[concept_cols][vision_codes.concept_id.isin(odd_vision_entries)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b09d2e9-5313-44f1-94b4-d0960ba57f13",
   "metadata": {},
   "source": [
    "* probably plenty more non-vision related codes in here\n",
    "* more thought needs to go into what cohort's we're defining here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68709ea-b11d-4e7b-a468-141ef594f7c0",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "***Step 1**: select a cohort of patients who have had this risk factor*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5045bd8b-9451-4d27-bae7-2b3f4917b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE `CB_1741_Relins.speech_person_codes` AS\n",
    "SELECT *  FROM `CB_1741_Relins.speech_codes` asd \n",
    "LEFT JOIN `CB_FDM_PrimaryCare_V7.tbl_srcode` p\n",
    "ON asd.concept_code = p.snomedcode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c07416-af0d-4979-a10f-714a82b54e8c",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "*For vision:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f206450b-95be-4f6c-a1a4-9db65c29335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE `CB_1741_Relins.vision_person_codes` AS\n",
    "SELECT *  FROM `CB_1741_Relins.vision_codes` asd \n",
    "LEFT JOIN `CB_FDM_PrimaryCare_V7.tbl_srcode` p\n",
    "ON asd.concept_code = p.snomedcode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2dcdd8-f459-48dd-9ab5-59f2a6f32728",
   "metadata": {},
   "source": [
    "* logic of these two queries seems to work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17e353a-9947-460f-9997-95cd88f92dcc",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "*For DCD:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380641af-521f-468e-b348-9ab68ddfa4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE `CY_1401_Elshehaly.dcd_person_codes` AS\n",
    "SELECT *  FROM `CY_1401_Elshehaly.dcd_assessment_concepts_expanded` asd \n",
    "LEFT JOIN `CY_FDM_PrimaryCare_V6.tbl_SRCode` p\n",
    "ON asd.concept_code = p.src_snomedcode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8034b1b5-0529-4b85-b4c5-444c9309d622",
   "metadata": {},
   "source": [
    "* I don't have the script to create the `dcd_assessment_concepts_expanded` table so I'll leave this out for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9652383-b151-4115-ac8d-e2120477c2d1",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "***Step 2**: add person details so we can find out their age at the time of risk*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd262e51-3f67-4aec-a399-50fd1b431a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE `CB_1741_Relins.speech_person_codes_v2` AS\n",
    "SELECT pc.*, p.birthplace, p.datebirth, p.ethnicity, p.gender, \n",
    "    p.languagespoken, p.rowidentifier AS patientRowID, p.soa,  \n",
    "    p.speaksenglish, p.ward, p.spinematched \n",
    "FROM `CB_1741_Relins.speech_person_codes` pc \n",
    "LEFT JOIN `CB_FDM_PrimaryCare_V7.tbl_srpatient` p\n",
    "ON pc.person_id = p.person_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45406f5c-7e14-41bb-8425-5e19545b0f8a",
   "metadata": {},
   "source": [
    "* The `srpatient` table contains multiple entries per person, which results in many duplicate records for each of the individuals in the cohort. The initial `speech_person_codes` table has 1,618,489 rows - this increases to 5,487,100 rows after the join to the `srpatient` table. Assuming the logic of this is to add individual details of the person to each record of a clinical code, rather than duplicating each entry multiple times\n",
    "* This might be better done with the demographics table, but the provenence of that would require some investigation too"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97dd97b-ad3f-4660-a183-b42a9b8b33a4",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "*At this point we have over 271,000 unique person_id’s who have encountered one or more of the speech codes.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fe73f8-6744-48df-a539-4911d07a7ecf",
   "metadata": {},
   "source": [
    "* There are now 274k unique person_ids in the speech table with the new concepts and the V7 primary care dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e699582-ffd7-40f5-a134-ced299b4db0d",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "***Step 3**: now let’s filter by age at time of recording – only those records entered for young people (when they were younger than 19 years old) are kept*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca80063-0f57-4ece-90e8-e65f54918d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE `CB_1741_Relins.speech_person_codes_v3` AS\n",
    "SELECT *\n",
    "FROM `CB_1741_Relins.speech_person_codes_v2` pc\n",
    "WHERE DATE_DIFF(pc.dateevent, CAST(pc.datebirth AS DATE FORMAT 'yyyymm'), YEAR) < 19  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8248d1-aa4c-4c23-89c9-e18b7359550c",
   "metadata": {},
   "source": [
    "* logic of the SQL seems to work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0912d2-2727-4950-a963-0a5163d899a2",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "*At this point we have over 237,000 unique person_id’s which means a majority of the records were actually for CYP < 19 years old.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1600e282-1b5b-4af3-a63c-b6676aa53809",
   "metadata": {},
   "source": [
    "* new datasets result in ~239K unique person_ids < 19 y/o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b083e73-a388-44e4-bef1-03fc81759708",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "\n",
    "***Step 4**: Create a EHR for each person in this cohort*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9099d1b2-c4d7-43c6-95f8-2c5c8076567b",
   "metadata": {},
   "source": [
    "* this seems to be a bit strange - we just restricted the cohort to people who were under the age of 19 when a speech-related code was added to their health records. Now we're collecting the entire health record for all these individuals, so many of the entries in this table will be codes added after they were 19. I'm a bit confused by these inclusion criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c67bc03-94e3-40b1-83dc-7d0e2971715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE `CB_1741_Relins.speech_person_ehr` AS\n",
    "SELECT recs.* \n",
    "FROM (\n",
    "    SELECT DISTINCT person_id  \n",
    "    FROM `CB_1741_Relins.speech_person_codes_v3`\n",
    ") AS persons \n",
    "LEFT JOIN `CB_FDM_PrimaryCare_V7.tbl_srcode` recs\n",
    "ON persons.person_id = recs.person_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b5c3bd-bf7c-435b-93a5-4b324de35eb2",
   "metadata": {},
   "source": [
    "* logic of the SQL seems to work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa2c790-1a0e-4787-b011-44b68b6faab4",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "***Step 4b**: person details were lost in the query above, so we restore them here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e4a970-6da1-4be1-8ad3-9bc22e01328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE `CB_1741_Relins.speech_person_ehr_v2` AS\n",
    "SELECT ehr.*, person.concept_name, person.soa, person.speaksenglish, \n",
    "    person.ethnicity, person.gender, person.birthplace, \n",
    "    person.datebirth, person.languagespoken, person.ward\n",
    "FROM `CB_1741_Relins.speech_person_ehr` ehr \n",
    "LEFT JOIN `CB_1741_Relins.speech_person_codes_v3` person\n",
    "ON ehr.person_id = person.person_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195d52e-ac31-4874-a936-d577f0bbd4fa",
   "metadata": {},
   "source": [
    "* this duplicates every row in the original `speech_person_ehr` table over every row in the `speech_person_codes` table. The result is going from a ~107M row table to a 3 Billion row table!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c795275-2254-4568-ac6c-50e0d675aba0",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "***Step 5a**: Find the first encounter of the risk factor*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1a56b1-7052-4ef8-ab47-ef7a7c062113",
   "metadata": {},
   "source": [
    "* isn't clear what is meant by this - first encounter of ANY of the codes identified in each of the \"person_codes\" tables? First encounter FOR EACH of the codes encoundered in the \"person_codes\" tables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0c25c3-1abe-4f6d-8b29-8357c7657daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE `CB_1741_Relins.speech_person_first_encounter` AS\n",
    "SELECT DISTINCT person_id, snomedcode, ctv3text, idvisit, \n",
    "    MIN(dateeventrecorded) AS first_encountered\n",
    "FROM `CB_1741_Relins.speech_person_ehr_v2` ehr\n",
    "WHERE snomedcode IN (\n",
    "    SELECT DISTINCT snomedcode \n",
    "    FROM `CB_1741_Relins.speech_person_codes_v3`\n",
    ")\n",
    "GROUP BY person_id, snomedcode, idvisit, ctv3text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69246a8c-83cf-49b7-908b-19ed86107dae",
   "metadata": {},
   "source": [
    "* The `DISTINCT` statement insn't necessary as the query is already grouped by all the selected variables (if you remove the `DISTINCT` you get exactly the same result) - also not advisable to use a `DISTINCT` statement over multiple variables with grouping too - it's prone to errors\n",
    "* I'm not sure of the logic here - prior to this point we've been defining the \"risk factor\" as ANY of the numerous clinical codes in the \"codes\" tables. This query finds the earliest event record for ALL the unique combinations of person_id, snomedcode, ctv3text and idvisit. So for every individual, we'll potentially have multiple entries with the earliest date for every code recorded for each unique visit in their records. This doesn't make sense to me. Particularly grouping by visits - presumably you'll just end up with the same dates as you had in the original table as most visits won't span multiple dates\n",
    "* My intuition is that we're looking for the earliest record for each individual of one of the (in this example) speech \"codes\", which is a much simpler query\n",
    "* Probably need to discuss this as I can't really guess at what's supposed to be happening here - and given the complexity of the query and the size of the table, it's even harder to figure out what's going on with the results and if they're to be expected or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3bf087-d8a5-4735-89a0-d4d32676ae15",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "***Step 5b**: attach this information back to the EHR table (EDITED workflow here)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a13984-9562-42f6-8fc5-1fce4f641571",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE `CB_1741_Relins.speech_person_ehr_v3` AS\n",
    "SELECT ehr.*, f.first_encountered\n",
    "FROM `CB_1741_Relins.speech_person_ehr_v2` ehr \n",
    "LEFT JOIN `CB_1741_Relins.speech_person_first_encounter` f\n",
    "ON ehr.person_id = f.person_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab307a8-6222-4dda-bdaf-13a4c009345e",
   "metadata": {},
   "source": [
    "* again, there are several person_ids in the `speech_person_first_encouter` table with multiple associated records, so this query is creating a duplicate of the entire record for each person_id the `speech_person_ehr` for every duplicate entry in the `speech_person_first_encounter` table. The result is a 3 billion row table becomming a 6.5 billion row table, which I'm guessing certainly isn't intended.\n",
    "* It's hard to suggest a fix for this without knowing what supposed to be happening with the \"first encounter\" variable, but its likely we just want to join by both person_id and the other features were grouping over in the \"first encounter\" query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f19e31-b873-47e6-a4b7-bfc0fba032d3",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "***EDIT**: Attach the first diagnosed variable to the person_codes table because I ended up using it in the dashboard instead of the EHR one. NB: We still need to attach this to EHR so we can trace referrals after first encounter, etc. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38c77b-97f6-49d7-abb9-4afe58df03a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE `CB_1741_Relins.speech_person_codes_v4` AS\n",
    "SELECT ehr.*, f.first_encountered\n",
    "FROM `CB_1741_Relins.speech_person_codes_v3` ehr \n",
    "LEFT JOIN `CB_1741_Relins.speech_person_first_encounter` f\n",
    "ON ehr.person_id = f.person_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f4fede-3d7f-42bc-8dc6-86cc0acb83c1",
   "metadata": {},
   "source": [
    "* again this will create the same issue with duplicated records as above - 4M rows becomes 8M rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf0db21-74e6-48cf-9865-b9536dd22f19",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "***Step 6**: attach post codes (EDITED)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308ffd94-ecca-4eb5-b027-b6a453c0bbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE `CB_1741_Relins.speech_person_ehr_v4` AS\n",
    "SELECT * \n",
    "FROM `CB_1741_Relins.speech_person_ehr_v3` fd \n",
    "LEFT JOIN `CB_1401_Elshehaly.lsoa_to_postcode` po\n",
    "ON fd.soa = po.LSOA_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f527ce7f-5a35-4db1-9ba9-27971d9b9412",
   "metadata": {},
   "source": [
    "* not sure how you can convert an LSOA to a postcode - LSOAs as I understand them potentially have many postcodes/postcode areas\n",
    "* Likely as a result of the above comment, in several cases there are multiple entries per `LSOA_code` in the `lsoa_to_postcode` table - again, for all of these examples the rows with corresponding LSOAs will be duplicated the number of times over that `LSOA_code` appears in the `lsoa_to_postcode` table - 6.5 Billion rows becomes 10 billion rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f23279e-ab84-447b-af06-97c162e57f32",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "***EDIT**:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed1f939-1da7-4330-afb1-208c963a892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE `CB_1741_Relins.speech_person_codes_v5` AS\n",
    "SELECT * \n",
    "FROM `CB_1741_Relins.speech_person_codes_v4` fd \n",
    "LEFT JOIN `CB_1401_Elshehaly.lsoa_to_postcode` po\n",
    "ON fd.soa = po.LSOA_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddac37cc-cd75-4853-8e0c-c775191ed2fc",
   "metadata": {},
   "source": [
    "* as per above 8M rows becomes 12M rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a07ce15-00b8-4369-8511-e56cf2004680",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "***Step 7**: attach months elapsed between event and first encounter and also attach the person’s age at visit (both are derived columns) (EDITED)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685f9b52-9a37-47f3-b43b-faae659a8568",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE `CB_1741_Relins.speech_person_ehr_v5` AS\n",
    "SELECT *, DATE_DIFF(dateevent, \n",
    "                    CAST(datebirth AS DATE FORMAT 'yyyymm'), \n",
    "                    YEAR) AS age_at_encounter, \n",
    "          DATE_DIFF(dateevent,  \n",
    "                    first_encountered,  \n",
    "                    MONTH) AS months_elapsed\n",
    "FROM `CB_1741_Relins.speech_person_ehr_v4` ehr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e071978b-7ac8-4601-9fc8-541ea3e3082f",
   "metadata": {},
   "source": [
    "* `age_at_encounter` seems fine logic wise\n",
    "* the `months_elapsed` variable exemplifes the issues above with the `first_encountered` logic - several values are negative - as said above, needs some more thought about what information we're tyring to capture here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9238141-afdd-4492-932b-6ad69ed0f118",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "***EDIT**:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de44368-9652-4b06-aca7-bcbcfe06b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE `CB_1741_Relins.speech_person_codes_v6` AS\n",
    "SELECT *, DATE_DIFF(dateevent, \n",
    "                    CAST(datebirth AS DATE FORMAT 'yyyymm'), \n",
    "                    YEAR) AS age_at_encounter, \n",
    "          DATE_DIFF(dateevent, \n",
    "                    first_encountered, \n",
    "                    MONTH) AS months_elapsed\n",
    "FROM `CB_1741_Relins.speech_person_codes_v5` ehr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cddf7ad-a32b-4c90-9701-eefc291d0e84",
   "metadata": {},
   "source": [
    "* same as above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeb10a5-3e07-40e1-a702-b3b70691a38d",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "***Step 8**: Calculating summaries for the main CLEVER panel:* \n",
    "\n",
    "*calculate the proportion of people in this cohort who also exist in the milestone cohort. In this case, the milestone is Autism diagnosis*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a527b1cc-a3b4-45e3-9e91-080523d86a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT DISTINCT person_id \n",
    "FROM `CY_1401_Elshehaly.speech_person_first_encounter` sp\n",
    "WHERE EXISTS (\n",
    "    SELECT DISTINCT person_id \n",
    "    FROM `CY_1401_Elshehaly.asd_person_first_diagnosis` asd\n",
    "    WHERE sp.person_id = asd.person_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25606625-ded3-4bfa-86db-a66c1771b4d6",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "*Results in 4625*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f8fea0-f0d1-431e-9320-e3fd57e46206",
   "metadata": {},
   "source": [
    "* I don't have any detials of how the `asd_person_first_diagnosis` is generated so it's hard to say exactly what's going on here \n",
    "* The logic works here in terms of \"count the number of people in this table that appear in that table\", but as per above comments on the `asd_person_first_diagnosis`, I don't know if this is a sensible cohort to be summarising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c3c6b5-b64b-467b-8910-775656b47d95",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "*calculate the proportion of people in this cohort who have had a referral following the first encounter event (this will include all referrals but let’s see if we can pursue further filtering to see if any of the referrals were relevant to autism)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7807a784-b096-4783-8e29-df074628fdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT DISTINCT person_id\n",
    "FROM `CY_1401_Elshehaly.speech_person_ehr` ehr\n",
    "WHERE (src_ctv3text LIKE '%referral%' OR src_ctv3text LIKE '%Referral%')\n",
    "AND DATE_DIFF(src_dateevent, first_encountered, MONTH) < 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc69227-aedc-4e86-80aa-c41401ef26ae",
   "metadata": {},
   "source": [
    "* issues with `first_encountered` carry forward\n",
    "* will take some work to validate all the codes that are pulled out of the health records when searching for \"referral\" - don't have time for that at the moment but will be something to consider later\n",
    "\n",
    "The rest of the workflow I can't replicate without the code for the `social_person_codes` or without spending a lot of time reverse engineering the workflow, which would probably not be a good use of time. Best to discuss a way forward before we do any more work validating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132e1146-1309-4737-a288-c91e2b06d07a",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "***NOT INCLUDED HERE**: is a repetition of the above workflow to create a table social_person_codes which holds CYP records for those with social and behavioural concerns.*\n",
    "\n",
    "***STEP 10**: Merge both tables:*\n",
    "\n",
    "*First let’s add a label for each table to know where each record originates*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef440da0-3005-46b1-a48a-100700af19c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE `CY_1401_Elshehaly.social_person_codes` AS\n",
    "SELECT pc.*, ifnull(tbl_src, \"social\") AS table_source\n",
    "FROM `CY_1401_Elshehaly.social_person_codes` pc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccb4f85-bd0d-4bbf-997e-c25cc07af69d",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "*do the same thing for each table, adding the corresponding label to the table_source field.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829e900f-33f3-4f2f-aab4-837efdf0bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSERT INTO `CY_1401_Elshehaly.speech_and_social_person_codes` (\n",
    "    person_id, concept_id, concept_code, concept_name, src_rowidentifier, \n",
    "    src_dateevent, src_ctv3code, src_ctv3text, src_snomedcode, src_idorganisation, \n",
    "    src_idevent, src_idreferralin, src_idappointment, src_idvisit, care_site_id, \n",
    "    provider_id, procedure_source_concept_id,  observation_source_concept_id, \n",
    "    measurement_source_concept_id, src_soa,  src_speaksenglish,  src_ethnicity, \n",
    "    src_gender, src_birthplace, src_datebirth, src_languagespoken, src_ward,  \n",
    "    first_encountered, LSOA_code, postcode, age_at_encounter, months_elapsed, \n",
    "    table_source\n",
    ")\n",
    "SELECT person_id, concept_id, concept_code, concept_name, src_rowidentifier, \n",
    "    src_dateevent, src_ctv3code, src_ctv3text, src_snomedcode, src_idorganisation, \n",
    "    src_idevent, src_idreferralin, src_idappointment, src_idvisit, care_site_id, \n",
    "    provider_id, procedure_source_concept_id,  observation_source_concept_id, \n",
    "    measurement_source_concept_id, src_soa,  src_speaksenglish,  src_ethnicity, \n",
    "    src_gender, src_birthplace, src_datebirth, src_languagespoken, src_ward,  \n",
    "    first_encountered, LSOA_code, postcode, age_at_encounter, months_elapsed, \n",
    "    table_source\n",
    "FROM `CY_1401_Elshehaly.speech_person_codes`"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "myenv",
   "name": "r-cpu.4-2.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-2:m110"
  },
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
